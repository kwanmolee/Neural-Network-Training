{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>------------ Getting Started ------------</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from __future__ import print_function\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1</center>\n",
    "##### Construct a 5 Ã— 3 tensor and print it with the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8736e+17, 3.0907e-41, 5.7453e-44],\n",
      "        [0.0000e+00,        nan, 1.8040e+28],\n",
      "        [1.3733e-14, 6.4076e+07, 2.0706e-19],\n",
      "        [7.3909e+22, 2.4176e-12, 1.1625e+33],\n",
      "        [8.9605e-01, 1.1632e+33, 5.6003e-02]]) \n",
      "\n",
      "The type of x is <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5 , 3)\n",
    "print(x,\"\\n\")\n",
    "print(\"The type of x is %s\" %type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    ">\n",
    ">##### 1. Initialization of x\n",
    "1. By entering the size $(5,3)$, the Tensor with the corresponding size is created.\n",
    "2. Actually, it is an un-initialized Tensor. Tensor is a data structure representing multi-dimensional array, which is similar to NumPy ndarray.\n",
    "3. It can be seen that the elements in Tensor are all floats.\n",
    ">\n",
    ">##### 2. Type of x\n",
    "1. The type of $x$ is <class 'torch.Tensor'>. \n",
    "2. By default, the Tensor is created with the elements in type of 'float'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>2</center>\n",
    "##### Construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1025, 0.7385, 0.0492],\n",
      "        [0.1652, 0.0318, 0.1855],\n",
      "        [0.6707, 0.1828, 0.6747],\n",
      "        [0.1308, 0.5665, 0.3272],\n",
      "        [0.0068, 0.9046, 0.5571]]) \n",
      "\n",
      "Type of y is: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5 , 3)\n",
    "print(y,\"\\n\")\n",
    "print(\"Type of y is: %s\" %type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y=torch.randn(5,3) is: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y_ = torch.randn(5 , 3)\n",
    "print(\"Type of y=torch.randn(5,3) is: %s\" %type(y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    ">$y = torch.rand(5,3)$<p>$y\\_ = torch.randn(5,3)$\n",
    ">##### 1. Distribution of random values of y and y_ \n",
    "1. y = torch.rand() returns a tensor filled with random numbers from a uniform distribution on the interval $[0,1)$. The shape of y will be the size defined in the parenthesis, in this case, $(5,3)$.\n",
    "2. y_ = torch.randn() returns a tensor filled with random numbers from a normal distribution with mean of $0$ and variance of $1$ (also called the standard normal distribution). The shape of y_ will be the size defined in the parenthesis, in this case, $(5,3)$.\n",
    ">\n",
    ">##### 2. Type of y and y_\n",
    "1. The type of y is <class 'torch.Tensor'>. \n",
    "2. The type of y_ is <class 'torch.Tensor'>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>3</center>\n",
    "##### Run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8736e+17, 3.0907e-41, 5.7453e-44],\n",
      "        [0.0000e+00,        nan, 1.8040e+28],\n",
      "        [1.3733e-14, 6.4076e+07, 2.0706e-19],\n",
      "        [7.3909e+22, 2.4176e-12, 1.1625e+33],\n",
      "        [8.9605e-01, 1.1632e+33, 5.6003e-02]], dtype=torch.float64)\n",
      "tensor([[0.1025, 0.7385, 0.0492],\n",
      "        [0.1652, 0.0318, 0.1855],\n",
      "        [0.6707, 0.1828, 0.6747],\n",
      "        [0.1308, 0.5665, 0.3272],\n",
      "        [0.0068, 0.9046, 0.5571]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "The types displayed when printing $x$ and $y$ are both $ torch.float(64)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>4</center>\n",
    "##### We can also initialize directly tensors with prescribed values. Create the following two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[ -0.1859 , 1.3970 , 0.5236] ,\n",
    "                [ 2.3854 , 0.0707 , 2.1970] ,\n",
    "                [ -0.3587 , 1.2359 , 1.8951] ,\n",
    "                [ -0.1189 , -0.1376 , 0.4647] ,\n",
    "                [ -1.8968 , 2.0164 , 0.1092]])\n",
    "y = torch.Tensor([[ 0.4838 , 0.5822 , 0.2755] ,\n",
    "                [ 1.0982 , 0.4932 , -0.6680] ,\n",
    "                [ 0.7915 , 0.6580 , -0.5819] ,\n",
    "                [ 0.3825 , -1.1822 , 1.5217] ,\n",
    "                [ 0.6042 , -0.2280 , 1.3210]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x is: torch.Size([5, 3])\n",
      "The shape of y is: torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of x is: %s\" %(x.shape,))\n",
    "print(\"The shape of y is: %s\" %(y.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>5</center>\n",
    "##### You can stack the two 2d tensors in a 3d tensor as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of z = torch.stack((x,y)) is: torch.Size([2, 5, 3])\n",
      "The shape of z = torch.cat((x, y), 0) is: torch.Size([10, 3])\n",
      "The shape of z = torch.cat((x, y), 1) is: torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x,y))\n",
    "z2 = torch.cat((x,y),0)\n",
    "z3 = torch.cat((x,y),1)\n",
    "print(\"The shape of z = torch.stack((x,y)) is: %s\" %(z.shape,))\n",
    "print(\"The shape of z = torch.cat((x, y), 0) is: %s\" %(z2.shape,))\n",
    "print(\"The shape of z = torch.cat((x, y), 1) is: %s\" %(z3.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. __z = torch.stack((x,y))__ concatenates sequence of tensors along a new dimension \n",
    "2. __z = torch.cat((x, y), 0)__ concatenates the given sequence of tensors in the vertical dimension\n",
    "3. __z = torch.cat((x, y), 0)__ concatenates the given sequence of tensors in the horizontal dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>6</center>\n",
    "##### Report the value of the element at the 5th row and 3rd column in the 2d tensor y, and try accessing the same element in the 3d tensor z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element in y is: tensor(1.3210)\n",
      "Element in z is: tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(\"Element in y is: %s\" %y[4,2])\n",
    "print(\"Element in z is: %s\" %z[1,4,2]) # access the first dimension "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>7</center>\n",
    "##### Similarly print all the elements corresponding to the 5th row and 3rd column in z. How many elements are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elements corresponding to 5th row and 3rd column in z are: tensor([0.1092, 1.3210])\n",
      "There are 2 elements totally\n"
     ]
    }
   ],
   "source": [
    "print(\"The elements corresponding to 5th row and 3rd column in z are: %s\" %z[:,4,2])\n",
    "print(\"There are %s elements totally\" %len(z[:,4,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>8</center>\n",
    "##### Adding two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Result of x+y is:\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "2: Result of torch.add(x,y) is:\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "3: Result of x.add(y) is:\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "4: Result of torch.add(x,y,out=x):\n",
      " tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "methods = {\"x+y\":x+y,\"torch.add(x,y)\":torch.add(x,y),\"x.add(y)\":x.add(y)}\n",
    "for ind,(name,val) in enumerate(methods.items()):\n",
    "    print(\"{0}: Result of {1} is:\\n{2}\".format(ind+1,name,val))\n",
    "\n",
    "torch.add(x,y,out=x)\n",
    "print(\"4: Result of torch.add(x,y,out=x):\\n %s\" %x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "They are printing the same outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>9</center>\n",
    "##### To reshape a tensor, you can use torch.view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([4, 4])\n",
      "y: torch.Size([16])\n",
      "z: torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4) \n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(\"x: {0}\\ny: {1}\\nz: {2}\".format(x.size(),y.size(),z.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. $x$ is the Tensor having random numbers from a standard normal distribution with the szie of $(4,4)$\n",
    "2. $y$ is the Tensor acquired by reshaping the size of $x$ from $(4,4)$ to $(16)$. $2$-dimension size is squeezed into one dimension\n",
    ">3. __Meaning of '-1'__<p>1) $z$ is the Tensor acquired by specifying only the number of columns. __'-1'__ means if there is any situation we  don't know how many rows we would like to build but are sure of the number of columns, then we can sepcify the dimension of rows to be __'-1'__. Of course we can extend this to Tensors with more dimensions but only ONE of the axis value can be __-1__.<p>2) Bascially, we assigning __'-1'__ to one dimension by letting the library to compute the exact number itself with the rest dimensions we have given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>10</center>\n",
    "##### Generate 2 random tensors x and y of dimensions 10Ã—10 and 2Ã—100 respectively, resize them s.t. the instruction torch.mm(x, y) performs a row vector by matrix multiplication resulting in a row vector of dimensions 1 Ã— 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Intuition\n",
    "1. The resulting row vector after matrix multiplication of $x$ and $y$ is in size $(1,2)$, which means the 1st dimension of $x$ should be $1$ and the 2nd dimension of $y$ should be $2$\n",
    "2. Using the size reshaping tool: view and functionality of '$-1$', we can easily complete this procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting matrix is: tensor([[-18.4881,  10.0033]]), the row vector of dimensions 1 x 2\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10,10)\n",
    "y = torch.randn(2,100)\n",
    "res = torch.mm(x.view(1,-1),y.view(-1,2))\n",
    "print(\"The resulting matrix is: %s, the row vector of dimensions %s x %s\" %(res,res.shape[0],res.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>------------ NumPy and PyTorch ------------</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>11</center>\n",
    "##### Run the below code snippet and report your observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is tensor([1., 1., 1., 1., 1.])\n",
      "Type of a is <class 'torch.Tensor'>\n",
      "\n",
      "b is [1. 1. 1. 1. 1.]\n",
      "Type of b is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(\"a is {0}\\nType of a is {1}\\n\".format(a,type(a)))\n",
    "b = a.numpy()\n",
    "print(\"b is {0}\\nType of b is {1}\".format(b,type(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. Type of $a$ is <class 'torch.Tensor'>\n",
    "2. Type of $b$ is <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>12</center>\n",
    "##### Add one to the first element of the tensor a from the previous question and report the newvalues of $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. Without making changes to $b$, its values change and align with those of $a$ automatically.\n",
    "2. They share their underlying memory locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>13</center>\n",
    "##### Compare the effect of each of these three instructions separately. For each of them, report the new values of $a$ and $b$. What are the similarities and differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.]) [3. 2. 2. 2. 2.]\n",
      "tensor([4., 3., 3., 3., 3.]) [4. 3. 3. 3. 3.]\n",
      "tensor([5., 4., 4., 4., 4.]) [4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a,b)\n",
    "a[:] += 1\n",
    "print(a,b)\n",
    "a = a.add(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "    1. Implementing a.add_(1):\n",
    "        1) all elements in 'a' plus 1\n",
    "        2) the values of elements in 'b' change and align with those of 'a' automatically\n",
    "    2. Implementing a[:] += 1:\n",
    "        1) all elements in 'a' plus 1\n",
    "        2) the values of elements in 'b' change and align with those of 'a' automatically\n",
    "    3. Implementing a = a.add(1):\n",
    "        1) all elements in 'a' plus 1\n",
    "        2) the values of elements in 'b' do not change since this command is to assign value to 'a'\n",
    "    4. Similarities: 'a' all + 1\n",
    "    5. Difference: b will change correspondingly in two former cases but b won't change if we implement a = a.add(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>14</center>\n",
    "##### Let us study the reverse operation, converting NumPy arrays to a Torch tensor. All the Torch tensors on the CPU (except a CharTensor) support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [2. 2. 2. 2. 2.] and type of a is: <class 'numpy.ndarray'>\n",
      "b: tensor([2., 2., 2., 2., 2.], dtype=torch.float64) and type of b is: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out = a)\n",
    "print(\"a: {0} and type of a is: {1}\".format(a,type(a)))\n",
    "print(\"b: {0} and type of b is: {1}\".format(b,type(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. $a$ is numpy.ndarray and $b$ is torch.Tensor transformed from $a$ \n",
    "2. When implementing __np.add(a,1,out=a)__, all elements in $a$ will plus one\n",
    "3. Similarly, since $b$ shares the same underlying memory location with $a$, the value of $b$ will also change and   keeps the same as that of $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>15</center>\n",
    "##### Torch tensors can be moved onto GPU deviceâ€™s memory using .to('cuda') or .cuda() and back to CPU device with .to('cpu') or .cpu(). Alternatively, a tensor can be directly allocated into the GPU using the device optional argument. Run the following script. Interpret each of these instructions. Compare the two allocation instructions for x and y, which one is the most efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([[ 3.1283, -0.1671,  3.0768],\n",
      "        [-0.7271, -0.7199, -1.4480],\n",
      "        [-0.0884, -1.6591, -1.4637],\n",
      "        [ 0.7962,  0.8212, -2.6538],\n",
      "        [ 0.9420,  0.1102,  1.4500]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# device = cuda if cuda is available, otherwise, device = cpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "# see device and check if cuda is available\n",
    "print(device)\n",
    "# Method 1: use .to() to move torch Tensors onto GPU device's memory\n",
    "x = torch.randn(5, 3).to(device) \n",
    "# Method 2: use device optional argument to move torch Tensors onto GPU device's memory\n",
    "y = torch.randn(5, 3, device=device) \n",
    "# addition\n",
    "z = x + y\n",
    "# print z and check its type\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. __Functionality of code above__:<br>\n",
    "1) automatically set __device__ as 'cuda' if it is available otherwise CPU<br>\n",
    "2) move Tensor $x$ onto GPU device's memory by using .to( )<br>\n",
    "3) move $y$ onto GPU device's memory by using device optional argument<br>\n",
    "4) addition of $x$ and $y$<br>\n",
    "5) check the additon result $z$ <br>\n",
    "2. From my perspective, the __device optional argument__ is more efficient since we automatically move Tensors onto GPU device's memory and make subsequent processing if GPU device is available.We can specify device at the begining and uniformly regulate all Tensors, which means we do not need to allocate Tensors to GPU one by one by using __.to('cuda')__. Notice that moving data from CPU to GPU is slow, so device optional argument enables us to do all the computations in GPU, and transfer the data back to CPU once all computations have been performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>16</center>\n",
    "##### Run and interpret the result of the following two instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.1283083  -0.16714847  3.0767784 ]\n",
      " [-0.72707176 -0.719889   -1.4479599 ]\n",
      " [-0.08835101 -1.659101   -1.4636607 ]\n",
      " [ 0.7961642   0.82118225 -2.6538312 ]\n",
      " [ 0.9419657   0.11021546  1.4499834 ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-11d5c486e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "As NumPy doesn't support GUP computation, it seems impossible for us to directly apply z.numpy(). The current method would be to move it onto CPU for computation. I have searched for other available methods, one of which will be the installation of the package of MinPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>------------ Autograd: automatic differentiation ------------</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>17</center> \n",
    "##### What is the requires grad attribute of y? What are the grad attributes of x and y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "y: tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(\"x: %s\\n\"%x)\n",
    "y = x + 2\n",
    "print(\"y: %s\\n\"%y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### CONCLUSION\n",
    "1. __requires_grad__ is the optonal attribute in type of __bool__: It indicates if autograd should record operations on the returned tensor. Default: False. In autograd, if any input Tensor of an operation has __requires_grad=True__, the computation will be tracked. After computing the backward pass, a gradient w.r.t. this tensor is accumulated into __.grad__ attribute.\n",
    "2. __grad__ is the attribute of gradient. The grad attributes of will be the Tensors holding the gradients with respect to $x$ and $y$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>18</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z:tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "f:27.0\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "f = z.mean()\n",
    "print(\"z:{0}\\nf:{1}\".format(z, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Inspect the resultand write the equation linking f with the four entries $x_1,x_2,x_3,x_4$ of $x$:\n",
    "\\begin{equation*}\n",
    "f = f(x_1,x_2,x_3,x_4) = \\frac{1}{4} \\sum_{i=1}^{4}z_i^2 = \\frac{1}{4} \\sum_{i=1}^{4}3y_{i}^{2} = \\frac{1}{4} \\sum_{i=1}^{4}3(x_{i}+2)^{2} \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>19</center>\n",
    "##### Because the variable f contains a single scalar, we can now back-propagate the gradient of f with respect to x into the variable x as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradiengt of f(x) w.r.s x is:\n",
      " tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "print(\"The gradiengt of f(x) w.r.s x is:\\n %s\" %x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>20</center>\n",
    "##### Figure out mathematically if autograd produces the correct answer by deriving, yourself, the partial derivatives for each $x_i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (\\nabla_x f(\\mathbf{x})))_i = \\frac {\\partial f(x_1, x_2, x_3, x_4)}{\\partial x_i}$$<br>\n",
    "$$ f(\\mathbf{x})= \\frac{1}{4} \\sum_{i=1}^{4}3(x_{i}+2)^{2} = \\frac{3}{4}\\left [(x_1+2)^2+(x_2+2)^2+(x_3+2)^2+(x_4+2)^2\\right] $$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_1} = \\frac{3(2+x_1)}{2}\\bigg\\rvert_{x_1 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_2} = \\frac{3(2+x_2)}{2}\\bigg\\rvert_{x_2 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_3} = \\frac{3(2+x_3)}{2}\\bigg\\rvert_{x_3 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_4} = \\frac{3(2+x_4)}{2}\\bigg\\rvert_{x_4 = 1} = 4.5$$<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    ">### CONCLUSION\n",
    "We can see that autograd produces the correct answers concerning all partial derivatives for each $x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>------------ MNIST Data Preparation ------------</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>21</center>\n",
    "##### Load and normalize MNIST testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain = MNISTtools.load(dataset = \"training\", path = \"/datasets/MNIST\")\n",
    "xtest, ltest = MNISTtools.load(dataset = \"testing\", path = \"/datasets/MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    \"\"\"\n",
    "    :param x: a collection of images\n",
    "    :type x: np.array int8\n",
    "    :return: modified version of images [-1,1]\n",
    "    :rtype: np.array float32\n",
    "    \"\"\"\n",
    "    return ((x-127.5)/127.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "xtest = normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>22</center>\n",
    "\n",
    "Torch expects that the input of a convolutional layer is stored in the following format\n",
    "        \n",
    "        Batch sizeÃ—Number of input channelsÃ—Image heightÃ—Image width\n",
    "\n",
    "The number of input channels in our case is 1 because MNIST is composed of grayscale images. It would have been 3 if the images were in RGB color. In deeper layers, the number of input channels will be the number of input feature maps. Reorganise the tensors xtrain and xtest accordingly.<br>\n",
    "__Hint__: Reshape them first with shape (28, 28, 1, 60000) and (28, 28, 1, 10000) respectively and then use np.moveaxis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain.shape: (60000, 1, 28, 28)\n",
      "xtest.shape: (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def np.moveaxis(a,source,destination):\n",
    "    Move axes of an array to new positions.\n",
    "    a : np.ndarray\n",
    "        The array whose axes should be reordered.\n",
    "    source : int or sequence of int\n",
    "        Original positions of the axes to move. These must be unique.\n",
    "    destination : int or sequence of int\n",
    "        Destination positions for each of the original axes. These must also be\n",
    "        unique.\n",
    "\"\"\"\n",
    "xtrain = np.moveaxis(xtrain.reshape(28,28,1,60000),[-1,-2],[0,1])\n",
    "xtest = np.moveaxis(xtest.reshape(28,28,1,10000),[-1,-2],[0,1])\n",
    "print(\"xtrain.shape: %s\\nxtest.shape: %s\" %(xtrain.shape,xtest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>23</center>\n",
    "##### Check that your data are well reorganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of image with index 42: 7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "MNISTtools.show(xtrain[42,0,:,:])\n",
    "print(\"The label of image with index 42: %s\" %ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "The procedure of data reshaping and axis moving is correct since the digit in the plot corresponds to its label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>24</center>\n",
    "##### Finally wrap all the data into torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>---- Convolutional Neural Network (CNN) for MNIST classification ---</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>25</center>\n",
    "##### Determine the size of the feature maps after each convolution and maxpooling operation. How many input units does the third layer have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "table td, table th, table tr {text-align:center !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "table td, table th, table tr {text-align:center !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### COMPUTATION\n",
    "(a)Convolution layer 1<br>\n",
    "(1) $K=5 \\rightarrow Output Size: [W_0-K+1]\\times[H_0-K+1] = [28-5+1]\\times[28-5+1] = [W_1]\\times [H_1] = 24 \\times 24$ <br>\n",
    "(2) $L=2 \\rightarrow Output Size: [W_1/L]\\times[H_1/L] = [24/2] \\times [24/2] = [W_2]\\times [H_2] = 12 \\times 12$ <br>\n",
    "(b)Convolution layer 2<br>\n",
    "(3) $K=5 \\rightarrow Output Size: [W_2-K+1]\\times[H_2-K+1] = [12-5+1]\\times[12-5+1]= [W_3]\\times [H_3] = 8 \\times 8$ <br>\n",
    "(4) $L=2 \\rightarrow Output Size: [W_3/L]\\times[H_3/L] = [8/2] \\times [8/2]= [W_4]\\times [H_4] = 4 \\times 4$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "|Operation|Number of Feature Map|Size of Feature Map|\n",
    "|---|---|---|\n",
    "|__INPUT__|$1$ | $28 \\times 28$|\n",
    "|__CONV1__|$6$ | $24 \\times 24$|\n",
    "|__POOL1__|$6$ | $12 \\times 12$|\n",
    "|__CONV2__|$16$ |$8 \\times 8$|\n",
    "|__POOL2__|$16$ |$4 \\times 4$|\n",
    ">\n",
    ">##### There are $16\\times16=256$ input units in the third layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>26</center>\n",
    "Note that you just have to define the __forward__ function, and the __backward__ function (where __gradients__ are computed) will be automatically defined for you using __autograd__. You can use any of the Torch tensor operations in the forward function. For more details, please refer to [the documentation](https://pytorch.org/docs/stable/nn.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn. Module\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        \"\"\"\n",
    "        Convolution Layer \n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # N = 1, C = 6, K = 5\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # N = 6, C = 16, K = 5\n",
    "        \"\"\"\n",
    "        Fully-connected Layer \n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(16*4*4,120) # 16 4x4 feature maps = 256 input units -> 120 output units\n",
    "        self.fc2 = nn.Linear(120,84) #  120 input units -> 84 output units\n",
    "        self.fc3 = nn.Linear(84,10) #  84 input units -> 10 output units\n",
    "            \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        2 convolution layers followed by relu + maxpooling(L = 2)\n",
    "        \"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = x.view(-1,self.num_flat_features(x)) # determine the number of batches by number of Tensors in one batch\n",
    "        \"\"\"\n",
    "        2 fulling connected layers followed by reulu\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size) # products of all elements along the axis\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>27</center>\n",
    "##### The learnable parameters of a model are returned by net.parameters(). Run the following and interpret the results<br> What are the learnable parameters? Are gradients going to be tracked by autograd for all parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "1 conv1.bias torch.Size([6]) True\n",
      "2 conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "3 conv2.bias torch.Size([16]) True\n",
      "4 fc1.weight torch.Size([120, 256]) True\n",
      "5 fc1.bias torch.Size([120]) True\n",
      "6 fc2.weight torch.Size([84, 120]) True\n",
      "7 fc2.bias torch.Size([84]) True\n",
      "8 fc3.weight torch.Size([10, 84]) True\n",
      "9 fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for idx,(name, param) in enumerate(net.named_parameters()):\n",
    "    print(idx, name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "|Index|Layer|Meaning of Parameter Size|\n",
    "|---|---|---|\n",
    "|__0__|__Convolution Layer 1__ |Number of __[output channels, input channels, kernel width, kernel height]__|\n",
    "|__1__|__Convolution Layer 1__|__bias__|\n",
    "|__2__|__Convolution Layer 2__|Number of __[output channels, input channels, kernel width, kernel height]__|\n",
    "|__3__|__Convolution Layer 2__|__bias__|\n",
    "|__4__|__Fully Connected Layer 1__|Number of __[output units, input units]__|\n",
    "|__5__|__Fully Connected Layer 1__|__bias__|\n",
    "|__6__|__Fully Connected Layer 2__|Number of __[output units, input units]__|\n",
    "|__7__|__Fully Connected Layer 2__|__bias__|\n",
    "|__8__|__Final Layer__|Number of __[output units, input units]__|\n",
    "|__9__|__Final Layer__|__bias__|\n",
    ">\n",
    ">##### The learnable paramters are:\n",
    "    Weight and bias for two convolution layers, two fully connected layers and one final layer(fully connected layer 3)\n",
    ">##### Gradients are going to be tracked by autograd for all parameters:\n",
    "    The .requires_grad attribute is True for all learnable parameters shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>28</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that __with torch.no grad()__ is used to avoid tracking for gradient during testing and then save some computation time, refer to [the documentation](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad). Run the following and interpret the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    yinit = net(xtest) # equivalent to yinit = net.forward(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial test accuracy: tensor(9.8000)\n"
     ]
    }
   ],
   "source": [
    "# return tuple (max,max_indices) \n",
    "# max: return the maximum value of all elements in the Tensor; max_indices: corresponding indices of max vals\n",
    "_, lpred = yinit.max(1) # dim = 1 / column\n",
    "init_acc = 100 * (ltest == lpred).float().mean()\n",
    "print(\"Initial test accuracy: %s\" %init_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "1. __yinit__ is the Tensor with size of(10000,10) acuqired from forward pass. There are 10000 examples, each of which corresponds to a row vector. The index of maximum value in the row vector is the predicted label for that example.\n",
    "2. __yinit.max(1)__<br>\n",
    "1) dim = 1 means the dimension to reduce<br>\n",
    "2) this function returns the tuple(max,max_indices)<br>\n",
    "3) tuple[0] = max is the Tensor storing the maximum values in all test samples<br>\n",
    "4) tuple[1] = max_indices is the Tensore storing the indices corresponding to maximum values in all test samples.These indices are the predicted labels for all test examples after forward pass.<br>\n",
    "3. **_, lpred = yinit.max(1)**: get the predicted labels for test examples\n",
    "4. __100 * (ltest == lpred).float().mean()__<br>\n",
    "1) ltest == lpred: return 1 and 0 for correct classification and misclassfication<br>\n",
    "2) (ltest == lpred).float(): transform results into floats<br>\n",
    "3) (ltest == lpred).float().mean(): returns the mean value, which is the probability of correct classification<br>\n",
    "4) 100 * (ltest == lpred).float().mean(): express the probability of accuracy in percentage<p>\n",
    "5. We can see that the accuracy rate is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>29</center>\n",
    "##### We will use (Mini-Batch) Stochastic Gradient Descent (SGD) with cross-entropy and momentum\n",
    "\n",
    "For more details, refer to [the documentation 1](https://pytorch.org/docs/stable/nn.html) and [the documentation 2](https://pytorch.org/docs/stable/optim.html). Note that PyTorchâ€™s __CrossEntropyLoss__ is the composition of a __softmax__ activation with __the standard cross-entropy loss__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B = 100, gamma =.001, rho =.9): \n",
    "    \"\"\"\n",
    "    : T - epochs\n",
    "    : B - mini batch size\n",
    "    : gamma - learning rate / step size\n",
    "    : rho - momentum\n",
    "    \"\"\"\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    NB = int(N/B) # Number of minibatches -> NB =  N / B = 60000 / 100 = 600\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = gamma, momentum = rho)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>30</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.302\n",
      "[1,   200] loss: 2.293\n",
      "[1,   300] loss: 2.288\n",
      "[1,   400] loss: 2.278\n",
      "[1,   500] loss: 2.262\n",
      "[1,   600] loss: 2.230\n",
      "[2,   100] loss: 2.155\n",
      "[2,   200] loss: 1.927\n",
      "[2,   300] loss: 1.294\n",
      "[2,   400] loss: 0.728\n",
      "[2,   500] loss: 0.559\n",
      "[2,   600] loss: 0.433\n",
      "[3,   100] loss: 0.368\n",
      "[3,   200] loss: 0.328\n",
      "[3,   300] loss: 0.280\n",
      "[3,   400] loss: 0.269\n",
      "[3,   500] loss: 0.243\n",
      "[3,   600] loss: 0.210\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B = 100, gamma = .001, rho = .9):\n",
    "    \"\"\"\n",
    "    : T - epochs\n",
    "    : B - mini batch size\n",
    "    : gamma - learning rate / step size\n",
    "    : rho - momentum\n",
    "    \"\"\"   \n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    NB = int(N/B) # Number of minibatches -> NB =  N / B = 60000 / 100 = 600\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = gamma, momentum = rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(NB) # shuffled range(NB = 600)\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = range(shuffled_indices[k] * B, shuffled_indices[k] * B + B)\n",
    "            inputs = xtrain[minibatch_indices]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "            \n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f'%\n",
    "                        (epoch + 1,k + 1,running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)\n",
    "print ('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>31</center>\n",
    "##### Re-evaluate the predictions of your trained network on the testing dataset. By how much did the accuracy improve compared to the initialization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after training: tensor(93.6400)\n",
      "Accuracy improved: 83.83999633789062\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    y_new = net(xtest)\n",
    "_, lpred_new = y_new.max(1) # dim = 1 / column\n",
    "test_acc = 100 * (ltest == lpred_new).float().mean()\n",
    "print(\"Test accuracy after training: %s\" %test_acc)\n",
    "print(\"Accuracy improved: %s\" %(test_acc - init_acc).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>32</center>\n",
    "##### Move the training data to GPU. Reinitialize a new network and transfer it to GPU simply as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.299\n",
      "[1,   200] loss: 2.287\n",
      "[1,   300] loss: 2.272\n",
      "[1,   400] loss: 2.241\n",
      "[1,   500] loss: 2.163\n",
      "[1,   600] loss: 1.836\n",
      "[2,   100] loss: 1.032\n",
      "[2,   200] loss: 0.580\n",
      "[2,   300] loss: 0.468\n",
      "[2,   400] loss: 0.356\n",
      "[2,   500] loss: 0.339\n",
      "[2,   600] loss: 0.295\n",
      "[3,   100] loss: 0.277\n",
      "[3,   200] loss: 0.260\n",
      "[3,   300] loss: 0.222\n",
      "[3,   400] loss: 0.217\n",
      "[3,   500] loss: 0.209\n",
      "[3,   600] loss: 0.196\n",
      "[4,   100] loss: 0.188\n",
      "[4,   200] loss: 0.176\n",
      "[4,   300] loss: 0.160\n",
      "[4,   400] loss: 0.166\n",
      "[4,   500] loss: 0.167\n",
      "[4,   600] loss: 0.155\n",
      "[5,   100] loss: 0.142\n",
      "[5,   200] loss: 0.140\n",
      "[5,   300] loss: 0.147\n",
      "[5,   400] loss: 0.133\n",
      "[5,   500] loss: 0.134\n",
      "[5,   600] loss: 0.123\n",
      "[6,   100] loss: 0.116\n",
      "[6,   200] loss: 0.123\n",
      "[6,   300] loss: 0.128\n",
      "[6,   400] loss: 0.117\n",
      "[6,   500] loss: 0.113\n",
      "[6,   600] loss: 0.111\n",
      "[7,   100] loss: 0.115\n",
      "[7,   200] loss: 0.100\n",
      "[7,   300] loss: 0.109\n",
      "[7,   400] loss: 0.097\n",
      "[7,   500] loss: 0.101\n",
      "[7,   600] loss: 0.098\n",
      "[8,   100] loss: 0.101\n",
      "[8,   200] loss: 0.095\n",
      "[8,   300] loss: 0.096\n",
      "[8,   400] loss: 0.096\n",
      "[8,   500] loss: 0.087\n",
      "[8,   600] loss: 0.094\n",
      "[9,   100] loss: 0.089\n",
      "[9,   200] loss: 0.090\n",
      "[9,   300] loss: 0.097\n",
      "[9,   400] loss: 0.087\n",
      "[9,   500] loss: 0.080\n",
      "[9,   600] loss: 0.084\n",
      "[10,   100] loss: 0.087\n",
      "[10,   200] loss: 0.082\n",
      "[10,   300] loss: 0.081\n",
      "[10,   400] loss: 0.072\n",
      "[10,   500] loss: 0.084\n",
      "[10,   600] loss: 0.080\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reinitiate\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn. Module\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # N = 1, C = 6, K = 5\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # N = 6, C = 16, K = 5\n",
    "\n",
    "        self.fc1 = nn.Linear(16*4*4,120) # 16 4x4 feature maps = 256 input units -> 120 output units\n",
    "        self.fc2 = nn.Linear(120,84) #  120 input units -> 84 output units\n",
    "        self.fc3 = nn.Linear(84,10) #  84 input units -> 10 output units\n",
    "            \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = x.view(-1,self.num_flat_features(x)) # determine the number of batches by number of Tensors in one batch\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size) # products of all elements along the axis\n",
    "\n",
    "net = LeNet().to(device)\n",
    "xtrain,ltrain = xtrain.to(device), ltrain.to(device)\n",
    "backprop_deep(xtrain, ltrain, net, T = 10)\n",
    "print ('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>33</center>\n",
    "##### Re-evaluate the predictions of your trained network on the testing dataset. By how much did the accuracy improve compared to 3 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after training: 97.70999908447266\n",
      "Accuracy improved from 3 epochs to 10 epochs: 4.069999694824219\n"
     ]
    }
   ],
   "source": [
    "xtest,ltest =  xtest.to(device), ltest.to(device)\n",
    "with torch.no_grad(): \n",
    "    y_new_2 = net(xtest)\n",
    "_, lpred_new_2 = y_new_2.max(1) # dim = 1 / column\n",
    "test_acc_2 = 100 * (ltest == lpred_new_2).float().mean()\n",
    "print(\"Test accuracy after training: %s\" %test_acc_2.item())\n",
    "print(\"Accuracy improved from 3 epochs to 10 epochs: %s\" %(test_acc_2 - test_acc.to(device)).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CONCLUSION\n",
    "The increase of accuracy concerning test set on the trained network from 3 epochs to 10 epochs is not obvious"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
